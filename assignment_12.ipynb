{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🐰🦊🐾content='🐰🦊🐾'\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory \n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1, streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "examples = [\n",
    "    {\"question\": \"Titanic\", \"answer\": \"🚢👩👨\"},\n",
    "    {\"question\": \"The Devil Wears Prada\", \"answer\": \"😈👩🏻👵🏻\"},\n",
    "    {\"question\": \"Elemental\", \"answer\": \"👨‍👩‍👧‍👦🔥💧\"},\n",
    "]\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm, \n",
    "    max_token_limit=120, \n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages([ \n",
    "    (\"human\", \"{question}\"),\n",
    "    (\"ai\", \"{answer}\")\n",
    "])\n",
    "\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a movie critic.If you were asked to answer about movie, you must closely follow the examples given and answer with three emojis that clearly represents the movie being asked about. Else, please respond kindly in sentence.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"), \n",
    "    example_prompt,\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "# 메모리 변수 획득 함수\n",
    "def load_memory(_):\n",
    "    return memory.load_memory_variables({})[\"history\"] \n",
    "\n",
    "chain = RunnablePassthrough.assign(history=load_memory) | prompt | llm\n",
    "\n",
    "def invoke_chain(question):\n",
    "\n",
    "    result = chain.invoke({\"question\": question})\n",
    "    memory.save_context({\"input\": question}, {\"output\": result.content})\n",
    "    print(result)\n",
    "\n",
    "invoke_chain(\"zootopia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👽👾🚀content='👽👾🚀'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"ailien\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zootopiacontent='Zootopia'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"Which movie was it I first asked?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
